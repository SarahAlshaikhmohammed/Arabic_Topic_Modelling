{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Topic Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim nltk pyarabic matplotlib pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pyarabic.araby as araby\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Download necessary NLTK data (stopwords)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data: List of Arabic texts related to business\n",
    "documents = [\n",
    "    \"الذكاء الاصطناعي يحلل البيانات الضخمة لاتخاذ قرارات استراتيجية في الأعمال\",\n",
    "    \"تستخدم الشركات المساعدات الذكية لتحسين خدمة العملاء وزيادة الكفاءة\",\n",
    "    \"يمكن للذكاء الاصطناعي التنبؤ بالاتجاهات السوقية وتحليل سلوك المستهلكين بدقة\",\n",
    "    \"تعتمد الشركات على الذكاء الاصطناعي لتحسين إدارة المخزون وتقليل التكاليف التشغيلية\",\n",
    "    \"يساهم الذكاء الاصطناعي في تحويل الأعمال الرقمية وتقديم منتجات جديدة مبتكرة\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess Arabic text\n",
    "def preprocess(text):\n",
    "    tokens = araby.tokenize(text)  # Tokenize the Arabic text\n",
    "    tokens = [araby.strip_tashkeel(word) for word in tokens]  # Remove diacritics\n",
    "    # Filter out stopwords and non-Arabic words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('arabic') and araby.is_arabicword(word)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the documents\n",
    "texts = [preprocess(document) for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary and Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and a corpus\n",
    "dictionary = corpora.Dictionary(texts)  # Map words to IDs\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # Convert texts to bag-of-words format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LDA (Latent Dirichlet Allocation) for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LDA model with 3 topics\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the Top Words Associated with Each Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print the top words for each topic\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    topic_words = topic[1].split(\" + \")\n",
    "    cleaned_words = [word.split(\"*\")[1].replace('\"', '') for word in topic_words]\n",
    "    print(f\"Topic {topic[0]}: {', '.join(cleaned_words)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
